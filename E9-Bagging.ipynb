{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9\n",
    "\n",
    "## Mashable news stories analysis\n",
    "\n",
    "Predicting if a news story is going to be popular\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>...</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>Popular</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://mashable.com/2014/12/10/cia-torture-rep...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>0.732620</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.844262</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-0.487500</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://mashable.com/2013/10/18/bitlock-kicksta...</td>\n",
       "      <td>447.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>0.653199</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.135340</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://mashable.com/2013/07/24/google-glass-po...</td>\n",
       "      <td>533.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.660377</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.775701</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://mashable.com/2013/11/21/these-are-the-m...</td>\n",
       "      <td>413.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>781.0</td>\n",
       "      <td>0.497409</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.677350</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.195701</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>-0.071429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://mashable.com/2014/02/11/parking-ticket-...</td>\n",
       "      <td>331.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.830357</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.55</td>\n",
       "      <td>-0.175000</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  timedelta  \\\n",
       "0  http://mashable.com/2014/12/10/cia-torture-rep...       28.0   \n",
       "1  http://mashable.com/2013/10/18/bitlock-kicksta...      447.0   \n",
       "2  http://mashable.com/2013/07/24/google-glass-po...      533.0   \n",
       "3  http://mashable.com/2013/11/21/these-are-the-m...      413.0   \n",
       "4  http://mashable.com/2014/02/11/parking-ticket-...      331.0   \n",
       "\n",
       "   n_tokens_title  n_tokens_content  n_unique_tokens  n_non_stop_words  \\\n",
       "0             9.0             188.0         0.732620               1.0   \n",
       "1             7.0             297.0         0.653199               1.0   \n",
       "2            11.0             181.0         0.660377               1.0   \n",
       "3            12.0             781.0         0.497409               1.0   \n",
       "4             8.0             177.0         0.685714               1.0   \n",
       "\n",
       "   n_non_stop_unique_tokens  num_hrefs  num_self_hrefs  num_imgs   ...     \\\n",
       "0                  0.844262        5.0             1.0       1.0   ...      \n",
       "1                  0.815789        9.0             4.0       1.0   ...      \n",
       "2                  0.775701        4.0             3.0       1.0   ...      \n",
       "3                  0.677350       10.0             3.0       1.0   ...      \n",
       "4                  0.830357        3.0             2.0       1.0   ...      \n",
       "\n",
       "   min_positive_polarity  max_positive_polarity  avg_negative_polarity  \\\n",
       "0               0.200000                   0.80              -0.487500   \n",
       "1               0.160000                   0.50              -0.135340   \n",
       "2               0.136364                   1.00               0.000000   \n",
       "3               0.100000                   1.00              -0.195701   \n",
       "4               0.100000                   0.55              -0.175000   \n",
       "\n",
       "   min_negative_polarity  max_negative_polarity  title_subjectivity  \\\n",
       "0                  -0.60              -0.250000                 0.9   \n",
       "1                  -0.40              -0.050000                 0.1   \n",
       "2                   0.00               0.000000                 0.3   \n",
       "3                  -0.40              -0.071429                 0.0   \n",
       "4                  -0.25              -0.100000                 0.0   \n",
       "\n",
       "   title_sentiment_polarity  abs_title_subjectivity  \\\n",
       "0                       0.8                     0.4   \n",
       "1                      -0.1                     0.4   \n",
       "2                       1.0                     0.2   \n",
       "3                       0.0                     0.5   \n",
       "4                       0.0                     0.5   \n",
       "\n",
       "   abs_title_sentiment_polarity  Popular  \n",
       "0                           0.8        1  \n",
       "1                           0.1        0  \n",
       "2                           1.0        0  \n",
       "3                           0.0        0  \n",
       "4                           0.0        0  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/albahnsen/PracticalMachineLearningClass/master/datasets/mashable.csv'\n",
    "train_df = pd.read_csv(url, index_col=0)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 61)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop(['url', 'Popular'], axis=1)\n",
    "y = train_df['Popular']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9.1\n",
    "\n",
    "Estimate a Decision Tree Classifier and a Logistic Regresion\n",
    "\n",
    "Evaluate using the following metrics:\n",
    "* Accuracy\n",
    "* F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar con train y validar con test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "#from sklearn.naive_bayes import GaussianNB\n",
    "#from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "#          'nb': GaussianNB(),\n",
    "#          'kn': KNeighborsRegressor()\n",
    "models = {'logr': LogisticRegression(),\n",
    "          'dt': DecisionTreeRegressor(),\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models.keys():\n",
    "    models[model].fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict test for each model\n",
    "y_pred = pd.DataFrame(index=y_test.index, columns=models.keys())\n",
    "for model in models.keys():\n",
    "    y_pred[model] = models[model].predict(X_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logr</th>\n",
       "      <th>dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2185</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2520</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3721</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3727</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      logr   dt\n",
       "1483     1  0.0\n",
       "2185     1  0.0\n",
       "2520     1  1.0\n",
       "3721     1  0.0\n",
       "3727     0  0.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "accur=[]\n",
    "f1sco=[]\n",
    "for i in range(y_pred.shape[1]):\n",
    "    accur.append(metrics.accuracy_score(y_pred.iloc[:,i],y_test))\n",
    "    f1sco.append(metrics.f1_score(y_pred.iloc[:,i], y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6206666666666667, 0.5493333333333333]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accur#, columns=models.keys())  #accur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6034843205574913, 0.546916890080429]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1sco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9.2\n",
    "\n",
    "Estimate 300 bagged samples\n",
    "\n",
    "Estimate the following set of classifiers:\n",
    "\n",
    "* 100 Decision Trees where max_depth=None\n",
    "* 100 Decision Trees where max_depth=2\n",
    "* 100 Logistic Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 595, 1064, 1993, ..., 3875, 3662, 2552]),\n",
       " array([3868,  768, 3522, ..., 3377, 1863, 3196]),\n",
       " array([ 261, 2818, 3130, ..., 1084, 2464, 1900]),\n",
       " array([2922, 2213, 4322, ..., 1449, 2241,  988]),\n",
       " array([1482,  793,  375, ...,  533, 2595,  300]),\n",
       " array([2954, 3187, 3436, ..., 3442, 2631, 2595]),\n",
       " array([3232, 3528, 3472, ..., 4302, 3067, 2005]),\n",
       " array([ 871, 1643, 2169, ...,  390,  861,  240]),\n",
       " array([2357, 3296, 1652, ...,  311, 2630, 2937]),\n",
       " array([2755, 4206, 1519, ..., 4130, 3388,  125]),\n",
       " array([3565, 1509,  214, ..., 2112, 4409, 2796]),\n",
       " array([2981, 2178, 2463, ...,  910, 1636,  649]),\n",
       " array([1783,  348, 4179, ...,  771, 3831, 4354]),\n",
       " array([3972, 2236, 3890, ..., 4146, 3808,  693]),\n",
       " array([2582,  356,  808, ..., 4102, 1514, 4325]),\n",
       " array([2072, 2516,  355, ..., 2937, 2821,  603]),\n",
       " array([3867, 3216, 3672, ..., 3151, 2916, 4282]),\n",
       " array([3410, 1785, 2293, ..., 4224,  872,  588]),\n",
       " array([1264,  902,  520, ..., 2805, 1751, 3713]),\n",
       " array([3977, 4140,  232, ..., 4267, 2168, 3165]),\n",
       " array([1058,  835,   39, ..., 3750, 2078, 2381]),\n",
       " array([1791, 1557, 3768, ..., 2820,  183,  101]),\n",
       " array([3721,  966, 1206, ..., 2915, 1234, 2661]),\n",
       " array([ 391, 2602, 4288, ..., 2233, 2147, 2370]),\n",
       " array([1908,  950, 4073, ...,  127, 2829, 1909]),\n",
       " array([ 442, 4127, 3939, ..., 4393, 2057, 4319]),\n",
       " array([ 148,  856, 2480, ...,  457, 1075, 4060]),\n",
       " array([ 161, 1329, 3984, ..., 1465, 2655,  290]),\n",
       " array([1749, 1312,  258, ..., 4033,  566, 1911]),\n",
       " array([ 367, 1003, 1905, ..., 4319, 3497, 1302]),\n",
       " array([ 941, 2284,   50, ..., 3770,  402, 1321]),\n",
       " array([2067, 4422, 1139, ..., 4330, 2624, 3234]),\n",
       " array([2012, 2407, 1408, ..., 4422, 4223,  191]),\n",
       " array([ 656, 1445, 2768, ..., 4115, 4122, 1131]),\n",
       " array([2550, 3954, 3697, ..., 1688,  203, 3906]),\n",
       " array([3824,  974, 2826, ..., 4295, 4366, 3064]),\n",
       " array([3061, 1174, 2520, ..., 4399, 3314, 1161]),\n",
       " array([3262,  234,  537, ..., 3280, 3203,  828]),\n",
       " array([1291, 1734,  917, ...,  217, 2944, 4141]),\n",
       " array([1537,   77, 4242, ..., 1944,  768, 3085]),\n",
       " array([1289, 4004, 3669, ..., 1085, 1771, 3481]),\n",
       " array([4425, 1339, 3248, ...,  744, 4201, 2989]),\n",
       " array([4355, 4488,  675, ..., 1250, 1106, 2818]),\n",
       " array([4219, 3470, 1527, ..., 2418, 1685, 1670]),\n",
       " array([1460, 1353, 2038, ...,  254, 2548, 3718]),\n",
       " array([ 577, 2037,   55, ..., 2595, 3689, 3487]),\n",
       " array([2917,  995, 3883, ...,  541, 4006, 1111]),\n",
       " array([ 766, 3701, 2519, ..., 2904, 4425, 1570]),\n",
       " array([3203, 3479, 2965, ..., 3219, 1136, 2252]),\n",
       " array([2294, 2972, 2301, ..., 4051, 1362, 3949]),\n",
       " array([ 307,  243, 2003, ..., 4320,  628, 4413]),\n",
       " array([ 967, 4115, 3376, ..., 1273, 2211,  742]),\n",
       " array([3895, 3998, 3360, ...,  971, 3126, 3082]),\n",
       " array([ 210, 3418, 2697, ..., 1741, 3289, 1225]),\n",
       " array([ 337, 2835, 2170, ...,  825,  439, 3610]),\n",
       " array([ 932, 2437,  900, ..., 3671, 2932, 3233]),\n",
       " array([3971, 2776, 1484, ..., 4081, 1020,  136]),\n",
       " array([2925,  172, 3786, ...,  768, 2047, 1653]),\n",
       " array([4020, 2433, 3315, ..., 2990, 4353,  782]),\n",
       " array([1361, 1173, 3762, ...,  660, 3085, 1446]),\n",
       " array([ 605, 1012,  693, ..., 3219, 3333,  163]),\n",
       " array([3873,  275, 4058, ..., 2882, 1666, 2902]),\n",
       " array([3119,  651, 3937, ...,  455, 3193, 3373]),\n",
       " array([2008, 4273, 3031, ..., 1700, 4015, 2708]),\n",
       " array([3475, 4382, 1110, ...,  748, 3527, 1392]),\n",
       " array([1977, 3370, 2785, ..., 1075, 4384, 1381]),\n",
       " array([3019, 1225,  421, ...,  815, 3961,  716]),\n",
       " array([ 764, 3271, 3233, ..., 3713, 2075,  240]),\n",
       " array([4450, 1631, 2533, ..., 1304, 3682, 1305]),\n",
       " array([ 502,  128,   64, ...,  676, 4139, 4252]),\n",
       " array([2775, 1973, 1229, ..., 2044,  715, 2408]),\n",
       " array([ 305, 2478, 3551, ..., 2764, 4354, 1164]),\n",
       " array([ 277, 4370, 1387, ...,  293,  759, 2260]),\n",
       " array([2547, 4217, 2467, ..., 3621, 1865,  432]),\n",
       " array([4222, 4072, 2840, ..., 3888, 2736, 2270]),\n",
       " array([2087, 4304, 1981, ..., 1943, 3346, 3925]),\n",
       " array([4226, 1772, 3544, ...,  139, 3456, 2096]),\n",
       " array([3533, 1027, 1858, ...,   79,  434,  206]),\n",
       " array([1060,  552, 2243, ...,  402, 3140,  996]),\n",
       " array([1110,  318, 2196, ..., 3663, 2771, 2917]),\n",
       " array([2575, 4068, 1651, ..., 1562,   80,  355]),\n",
       " array([4046, 2149,  867, ..., 3401,  966, 3048]),\n",
       " array([4029,  719, 1633, ...,   75, 4362, 1589]),\n",
       " array([3541, 4312,  274, ...,  685, 1376,  941]),\n",
       " array([2059, 4078, 1692, ..., 4146, 1825, 1111]),\n",
       " array([1586,  426, 1242, ..., 3864,  355,  227]),\n",
       " array([2645, 1295,  114, ..., 2284,  932, 1571]),\n",
       " array([ 247, 1245, 4106, ...,  800,   89, 2723]),\n",
       " array([4193, 2976, 2279, ..., 2844, 3223, 1595]),\n",
       " array([1616, 4295, 1415, ..., 1717, 2992,  823]),\n",
       " array([1007, 2076, 3080, ..., 3568, 2658, 4439]),\n",
       " array([2286, 1947, 3402, ..., 4177, 3951, 1892]),\n",
       " array([2642, 1889, 2808, ..., 1986, 4054,  686]),\n",
       " array([2109, 1310, 4360, ..., 3326,  171, 2806]),\n",
       " array([1141, 3824,  438, ..., 1529, 3921, 1155]),\n",
       " array([1942, 2023, 4263, ..., 1813,  690, 1805]),\n",
       " array([2831, 2944, 2593, ..., 1268, 2466, 2272]),\n",
       " array([ 510, 2427, 4034, ..., 3776,  657, 3856]),\n",
       " array([3523, 3203, 1804, ...,  160, 2273, 3239]),\n",
       " array([ 805, 2836, 2846, ..., 3462, 4097, 2944])]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# En 100 arboles con max_depth none\n",
    "#otros 100 para 2\n",
    "#otras 100 logisticas\n",
    "###Generar las muestras\n",
    "# set a seed for reproducibility\n",
    "np.random.seed(23)\n",
    "\n",
    "n_samples = X_train.shape[0]\n",
    "n_B = 100\n",
    "\n",
    "# create ten bootstrap samples (will be used to select rows from the DataFrame)\n",
    "samples = [np.random.choice(a=n_samples, size=n_samples, replace=True) for _ in range(1, n_B +1 )]\n",
    "samples2 = [np.random.choice(a=n_samples, size=n_samples, replace=True) for _ in range(1, n_B +1 )]\n",
    "samples3 = [np.random.choice(a=n_samples, size=n_samples, replace=True) for _ in range(1, n_B +1 )]\n",
    "samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generar los primeros 100 arboles con el dt y max_depth=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# grow each tree deep\n",
    "treereg = DecisionTreeClassifier(max_depth=None, random_state=123)\n",
    "\n",
    "# DataFrame for storing predicted price from each tree\n",
    "y_pred = pd.DataFrame(index=X_test.index, columns=[list(range(n_B))])\n",
    "\n",
    "# grow one tree for each bootstrap sample and make predictions on testing data\n",
    "for i, sample in enumerate(samples):\n",
    "    X_train_dt = X_train.iloc[sample, :]\n",
    "    y_train_dt = y_train.iloc[sample]\n",
    "    treereg.fit(X_train_dt, y_train_dt)\n",
    "    y_pred[i] = treereg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generar los siguientes 100 arboles con el dt y max_depth=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# grow each tree deep\n",
    "treereg = DecisionTreeClassifier(max_depth=2, random_state=123)\n",
    "\n",
    "# DataFrame for storing predicted price from each tree\n",
    "y_pred = pd.DataFrame(index=X_test.index, columns=[list(range(n_B))])\n",
    "\n",
    "# grow one tree for each bootstrap sample and make predictions on testing data\n",
    "for i, sample2 in enumerate(samples):\n",
    "    X_train_dt = X_train.iloc[sample2, :]\n",
    "    y_train_dt = y_train.iloc[sample2]\n",
    "    treereg.fit(X_train_dt, y_train_dt)\n",
    "    y_pred[i] = treereg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generar 100 regresiones logisticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# grow each tree deep\n",
    "treereg = DecisionTreeClassifier(max_depth=None, random_state=123)\n",
    "\n",
    "# DataFrame for storing predicted price from each tree\n",
    "y_pred = pd.DataFrame(index=X_test.index, columns=[list(range(n_B))])\n",
    "\n",
    "# grow one tree for each bootstrap sample and make predictions on testing data\n",
    "for i, sample3 in enumerate(samples):\n",
    "    X_train_dt = X_train.iloc[sample3, :]\n",
    "    y_train_dt = y_train.iloc[sample3]\n",
    "    treereg.fit(X_train_dt, y_train_dt)\n",
    "    y_pred[i] = treereg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9.3\n",
    "\n",
    "Ensemble using majority voting\n",
    "\n",
    "Evaluate using the following metrics:\n",
    "* Accuracy\n",
    "* F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9.4\n",
    "\n",
    "Estimate te probability as %models that predict positive\n",
    "\n",
    "Modify the probability threshold and select the one that maximizes the F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Estimar la probabilidad con bagging\n",
    "#mover el treshhold y maximizar el f1 score\n",
    "#probar aprox unos 20 y hacer la grafica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9.5\n",
    "\n",
    "Ensemble using weighted voting using the oob_error\n",
    "\n",
    "Evaluate using the following metrics:\n",
    "* Accuracy\n",
    "* F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiar a weighted voting utilizar el oob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9.6\n",
    "\n",
    "Estimate te probability of the weighted voting\n",
    "\n",
    "Modify the probability threshold and select the one that maximizes the F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9.7\n",
    "\n",
    "Estimate a logistic regression using as input the estimated classifiers\n",
    "\n",
    "Modify the probability threshold such that maximizes the F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
